# [성능 최적화 제목] - [간단한 설명]

> **Version**: 1.0.0
> **Last Updated**: YYYY-MM-DD
> **Author**: {작성자}

---

## 📌 기술 키워드 (Technical Keywords)

| 카테고리 | 키워드 |
|---------|--------|
| **최적화 영역** | `API Performance`, `Database Tuning`, `Cache Optimization`, `Infrastructure Scaling` |
| **측정 도구** | `JMeter`, `Gatling`, `k6`, `New Relic`, `Datadog`, `CloudWatch` |
| **최적화 기법** | `Query Optimization`, `Index Tuning`, `Connection Pooling`, `Caching`, `Async Processing` |
| **인프라** | `Auto Scaling`, `Load Balancer`, `CDN`, `Read Replica`, `Sharding` |
| **핵심 지표** | `TPS`, `Latency`, `P95/P99`, `Throughput`, `Error Rate`, `CPU/Memory Utilization` |

---

<!--
📝 작성 가이드:
- 제목: 최적화 대상과 결과를 한 줄로 (예: "API 응답 시간 90% 개선 및 대용량 트래픽 대응")
- 이 템플릿은 성능 문제 해결, 대용량 트래픽 대응, 인프라 최적화 경험을 문서화할 때 사용
- 이력서/포트폴리오용이므로 측정 데이터, 최적화 과정, 비즈니스 임팩트를 강조
- 반드시 Before/After 정량적 데이터 포함
-->

> **작성일**: YYYY년 MM월
> **프로젝트**: [프로젝트명]
> **도메인**: [관련 도메인/기술 스택]
> **최적화 대상**: [API/DB/인프라/시스템]

## 📋 목차

1. [성능 문제 발견](#1-성능-문제-발견)
2. [현재 상태 측정](#2-현재-상태-측정)
3. [병목 지점 분석](#3-병목-지점-분석)
4. [최적화 목표 설정](#4-최적화-목표-설정)
5. [최적화 전략 및 실행](#5-최적화-전략-및-실행)
6. [최종 성과 및 비즈니스 임팩트](#6-최종-성과-및-비즈니스-임팩트)
7. [지속 가능성 및 모니터링](#7-지속-가능성-및-모니터링)

---

## 1. 성능 문제 발견

<!--
어떻게 성능 문제를 인지했는가?
- 모니터링 알림? 사용자 불만? SLA 위반?
- 구체적인 지표와 임계값
-->

### 발견 경위
- **트리거**: [모니터링 알림, 사용자 불만, 장애 발생 등]
- **발견 시점**: [언제부터 문제가 시작되었는가]
- **영향 범위**: [전체 시스템/특정 API/특정 기능]

### 관찰된 증상
- **사용자 경험**: [페이지 로딩 지연, 타임아웃, 응답 없음 등]
- **시스템 지표**: [CPU 사용률, 메모리 사용률, DB 연결 수 등]
- **비즈니스 영향**: [전환율 하락, 이탈률 증가, 매출 감소 등]

### 비즈니스 임팩트
- **사용자 수**: [동시 접속자 수, DAU, MAU]
- **트래픽 규모**: [TPS, QPS, 데이터 전송량]
- **비즈니스 손실**: [예상 매출 손실, 사용자 이탈 등]

---

## 2. 현재 상태 측정

<!--
성능 최적화의 시작은 측정
- 부하 테스트 결과
- 프로파일링 데이터
- APM 지표
-->

### 측정 환경
- **테스트 도구**: [JMeter, Gatling, k6, Apache Bench 등]
- **인프라**: [서버 스펙, 인스턴스 수, DB 스펙]
- **부하 시나리오**: [동시 사용자 수, 요청 패턴]

### Baseline 성능 지표

| 지표 | 측정값 | 목표값 | 상태 |
|------|--------|--------|------|
| **평균 응답 시간** | [예: 2000ms] | [예: 200ms] | ❌ 목표 미달 |
| **P95 응답 시간** | [예: 5000ms] | [예: 500ms] | ❌ 목표 미달 |
| **P99 응답 시간** | [예: 10000ms] | [예: 1000ms] | ❌ 목표 미달 |
| **처리량 (TPS)** | [예: 100 TPS] | [예: 1000 TPS] | ❌ 목표 미달 |
| **에러율** | [예: 5%] | [예: 0.1%] | ❌ 목표 미달 |
| **CPU 사용률** | [예: 90%] | [예: <70%] | ❌ 과부하 |
| **메모리 사용률** | [예: 85%] | [예: <80%] | ❌ 과부하 |
| **DB 연결 수** | [예: 95/100] | [예: <80/100] | ⚠️ 위험 |

### 프로파일링 결과
```
[프로파일링 도구 결과 - 예: JProfiler, VisualVM, New Relic]

핫스팟 분석:
- Method A: 45% CPU 사용
- Method B: 30% CPU 사용
- DB Query X: 2000ms 평균 실행 시간
- Redis Get: 5ms 평균 실행 시간
```

### 주요 발견 사항
- **발견 1**: [예: DB 쿼리가 전체 응답 시간의 80% 차지]
- **발견 2**: [예: N+1 쿼리 문제로 단일 요청에 100개 쿼리 실행]
- **발견 3**: [예: 캐시 미사용으로 매번 DB 조회]

---

## 3. 병목 지점 분석

<!--
어디가 느린가? 왜 느린가?
- CPU/메모리/네트워크/DB 중 어디가 문제인지
- 상세 분석 결과
-->

### 시스템 계층별 분석

#### Application Layer
- **코드 레벨**: [비효율적 알고리즘, 불필요한 연산]
- **로직 복잡도**: [O(n²) 알고리즘, 중복 처리]
- **메모리 관리**: [메모리 누수, 과도한 객체 생성]

#### Database Layer
- **쿼리 성능**: [Slow Query 분석 결과]
- **인덱스 부재**: [Full Table Scan 발생]
- **N+1 문제**: [ORM 사용으로 인한 중복 쿼리]
- **잠금 경합**: [Lock 대기 시간, Deadlock]

#### Cache Layer
- **캐시 적중률**: [Hit Ratio, Miss Ratio]
- **캐시 전략**: [캐시 부재, TTL 부적절]
- **캐시 무효화**: [불필요한 캐시 삭제]

#### Network Layer
- **네트워크 지연**: [외부 API 호출, DB 통신]
- **직렬화/역직렬화**: [JSON 처리, 압축]
- **연결 풀**: [Connection Pool 고갈]

#### Infrastructure Layer
- **서버 리소스**: [CPU/메모리 부족]
- **스케일링 부재**: [단일 인스턴스 운영]
- **로드 밸런싱**: [트래픽 분산 부재]

### 병목 지점 우선순위

| 순위 | 병목 지점 | 영향도 | 개선 난이도 | 예상 효과 |
|------|-----------|--------|-------------|-----------|
| **1** | [예: DB 쿼리 최적화] | 🔴 Critical | ⭐⭐ | 응답 시간 70% 개선 |
| **2** | [예: 캐시 도입] | 🟠 High | ⭐⭐⭐ | DB 부하 90% 감소 |
| **3** | [예: 비동기 처리] | 🟡 Medium | ⭐⭐⭐⭐ | 처리량 300% 증가 |
| **4** | [예: 인프라 스케일 아웃] | 🟢 Low | ⭐ | 가용성 99.9% 달성 |

---

## 4. 최적화 목표 설정

<!--
SMART 원칙으로 목표 설정
- Specific (구체적)
- Measurable (측정 가능)
- Achievable (달성 가능)
- Relevant (관련성)
- Time-bound (기한)
-->

### 성능 목표

#### Primary Goals (필수 달성)
- **응답 시간**: [예: P95 2000ms → 200ms (90% 개선)]
- **처리량**: [예: 100 TPS → 1000 TPS (10배 증가)]
- **에러율**: [예: 5% → 0.1% (50배 개선)]

#### Secondary Goals (추가 목표)
- **인프라 비용**: [예: 월 $5000 → $3000 (40% 절감)]
- **가용성**: [예: 99% → 99.9% (Uptime 향상)]
- **확장성**: [예: 동시 접속자 1000명 → 10000명 지원]

### 제약 조건
- **기술적 제약**: [예: 레거시 시스템 유지, 특정 라이브러리 사용 필수]
- **비즈니스 제약**: [예: 무중단 배포 필수, 예산 한도]
- **시간 제약**: [예: 2주 내 완료]

### 성공 기준
- ✅ **P95 응답 시간 200ms 이하 달성**
- ✅ **부하 테스트에서 1000 TPS 처리 가능**
- ✅ **에러율 0.1% 이하 유지**
- ✅ **무중단 배포 완료**

---

## 5. 최적화 전략 및 실행

<!--
점진적 최적화 과정 기록
- 1차, 2차, 3차 최적화 단계별 실행
- 각 단계마다 측정 → 분석 → 개선 → 검증
-->

### 최적화 로드맵

```mermaid
graph LR
    A[1차: Quick Wins] --> B[2차: 구조 개선]
    B --> C[3차: 인프라 최적화]
    C --> D[4차: 고도화]
```

---

### 1차 최적화: Quick Wins (즉각 효과)

**목표**: 코드 레벨 개선으로 빠른 성과 달성

#### 적용 기법
- **쿼리 최적화**: [인덱스 추가, N+1 해결, Fetch Join]
- **캐시 도입**: [Redis, 로컬 캐시]
- **불필요한 연산 제거**: [중복 로직 제거, 알고리즘 개선]

#### Before (개선 전)
```java
// ❌ BAD: N+1 쿼리 문제
public List<OrderDTO> getOrders() {
    List<Order> orders = orderRepository.findAll();  // 1개 쿼리
    return orders.stream()
        .map(order -> {
            Customer customer = customerRepository.findById(order.getCustomerId()).get();  // N개 쿼리
            return OrderDTO.from(order, customer);
        })
        .collect(Collectors.toList());
}
```

#### After (개선 후)
```java
// ✅ GOOD: Fetch Join으로 1개 쿼리로 해결
public List<OrderDTO> getOrders() {
    List<Order> orders = orderRepository.findAllWithCustomer();  // 1개 쿼리 (Fetch Join)
    return orders.stream()
        .map(order -> OrderDTO.from(order, order.getCustomer()))
        .collect(Collectors.toList());
}
```

#### 측정 결과

| 지표 | Before | After | 개선율 |
|------|--------|-------|--------|
| 평균 응답 시간 | 2000ms | 800ms | **↓ 60%** |
| 쿼리 수 | 101개 | 1개 | **↓ 99%** |
| DB CPU | 80% | 40% | **↓ 50%** |

---

### 2차 최적화: 구조 개선 (중장기 효과)

**목표**: 아키텍처 레벨 개선으로 확장성 확보

#### 적용 기법
- **CQRS 패턴**: [읽기/쓰기 분리]
- **비동기 처리**: [메시지 큐 도입]
- **Connection Pool 튜닝**: [HikariCP 설정 최적화]
- **배치 처리**: [단건 처리 → 벌크 처리]

#### Before (개선 전)
```java
// ❌ BAD: 동기 처리로 응답 시간 지연
public void createOrder(OrderRequest request) {
    Order order = orderRepository.save(Order.from(request));
    paymentService.processPayment(order);  // 5초 소요
    emailService.sendConfirmation(order);   // 3초 소요
    smsService.sendNotification(order);     // 2초 소요
    // 총 10초 이상 소요
}
```

#### After (개선 후)
```java
// ✅ GOOD: 비동기 처리로 즉시 응답
public void createOrder(OrderRequest request) {
    Order order = orderRepository.save(Order.from(request));

    // 비동기 이벤트 발행 (즉시 반환)
    eventPublisher.publishEvent(new OrderCreatedEvent(order));

    // 총 200ms 소요 (DB 저장만)
}

// 이벤트 핸들러에서 비동기 처리
@Async
@EventListener
public void handleOrderCreated(OrderCreatedEvent event) {
    paymentService.processPayment(event.getOrder());
    emailService.sendConfirmation(event.getOrder());
    smsService.sendNotification(event.getOrder());
}
```

#### 측정 결과

| 지표 | Before | After | 개선율 |
|------|--------|-------|--------|
| 평균 응답 시간 | 800ms | 200ms | **↓ 75%** |
| 처리량 (TPS) | 100 TPS | 500 TPS | **↑ 400%** |
| 동시 처리 가능 요청 | 10개 | 50개 | **↑ 400%** |

---

### 3차 최적화: 인프라 최적화 (확장성)

**목표**: 대용량 트래픽 대응 및 가용성 확보

#### 적용 기법
- **Auto Scaling**: [부하에 따른 자동 확장]
- **Read Replica**: [읽기 부하 분산]
- **CDN 도입**: [정적 리소스 캐싱]
- **로드 밸런싱**: [트래픽 분산]

#### 인프라 아키텍처

**Before**:
```
┌─────────────┐
│   Client    │
└──────┬──────┘
       │
┌──────▼──────┐      ┌─────────────┐
│  App Server │─────▶│   MySQL DB  │
│  (Single)   │      │  (Single)   │
└─────────────┘      └─────────────┘
```

**After**:
```
┌─────────────┐
│   Client    │
└──────┬──────┘
       │
┌──────▼──────┐
│     CDN     │
└──────┬──────┘
       │
┌──────▼──────┐
│ Load Balancer│
└──┬────┬────┬┘
   │    │    │
┌──▼┐ ┌─▼┐ ┌─▼┐      ┌─────────────┐      ┌─────────────┐
│App│ │App│ │App│─────▶│MySQL Master │─────▶│MySQL Replica│
│ 1 │ │ 2 │ │ 3 │      │  (Write)    │      │   (Read)    │
└───┘ └───┘ └───┘      └─────────────┘      └─────────────┘
                              │
                        ┌─────▼─────┐
                        │   Redis   │
                        │  (Cache)  │
                        └───────────┘
```

#### 측정 결과

| 지표 | Before | After | 개선율 |
|------|--------|-------|--------|
| 처리량 (TPS) | 500 TPS | 2000 TPS | **↑ 300%** |
| 가용성 | 99% | 99.95% | **↑ 0.95%p** |
| 동시 접속자 | 1000명 | 10000명 | **↑ 900%** |
| 인프라 비용 | $5000/월 | $4000/월 | **↓ 20%** |

---

### 4차 최적화: 고도화 (지속 개선)

**목표**: 성능 모니터링 및 지속적 개선 체계 구축

#### 적용 기법
- **APM 도입**: [New Relic, Datadog, Scouter]
- **분산 트레이싱**: [Zipkin, Jaeger]
- **성능 대시보드**: [Grafana, Kibana]
- **알림 시스템**: [임계값 초과 시 자동 알림]

#### 모니터링 지표
- **Golden Signals**: Latency, Traffic, Errors, Saturation
- **Business Metrics**: 전환율, 이탈률, 매출
- **Infrastructure Metrics**: CPU, 메모리, 네트워크, 디스크

---

## 6. 최종 성과 및 비즈니스 임팩트

<!--
정량적/정성적 성과를 명확히
- Before/After 비교
- 비즈니스 임팩트
- 비용 절감 효과
-->

### 성능 개선 종합

| 지표 | Before | After | 개선율 | 목표 달성 |
|------|--------|-------|--------|-----------|
| **평균 응답 시간** | 2000ms | 150ms | **↓ 92.5%** | ✅ 목표 초과 달성 |
| **P95 응답 시간** | 5000ms | 200ms | **↓ 96%** | ✅ 목표 달성 |
| **P99 응답 시간** | 10000ms | 500ms | **↓ 95%** | ✅ 목표 초과 달성 |
| **처리량 (TPS)** | 100 TPS | 2000 TPS | **↑ 1900%** | ✅ 목표 초과 달성 |
| **에러율** | 5% | 0.05% | **↓ 99%** | ✅ 목표 초과 달성 |
| **CPU 사용률** | 90% | 50% | **↓ 44%** | ✅ 목표 달성 |
| **메모리 사용률** | 85% | 60% | **↓ 29%** | ✅ 목표 달성 |
| **DB 쿼리 수** | 101개/요청 | 1개/요청 | **↓ 99%** | ✅ 목표 초과 달성 |

### 비즈니스 임팩트

| 지표 | Before | After | 개선 |
|------|--------|-------|------|
| **사용자 이탈률** | 30% | 8% | **↓ 73%** |
| **페이지 전환율** | 2% | 5% | **↑ 150%** |
| **월간 매출** | $100K | $180K | **↑ 80%** |
| **동시 접속자** | 1000명 | 10000명 | **↑ 900%** |
| **사용자 만족도** | 3.2/5 | 4.7/5 | **↑ 47%** |

### 비용 절감 효과

| 항목 | Before | After | 절감액 |
|------|--------|-------|--------|
| **인프라 비용** | $5000/월 | $4000/월 | **-$1000/월** |
| **DB 비용** | $2000/월 | $1500/월 | **-$500/월** |
| **총 비용** | $7000/월 | $5500/월 | **-$1500/월 (21% 절감)** |
| **연간 절감액** | - | - | **$18000/년** |

### ROI 분석
- **투입 공수**: [예: 2주, 개발자 2명]
- **투입 비용**: [예: $10000 (인건비 + 인프라)]
- **연간 절감**: [예: $18000 (인프라) + $300000 (매출 증가)]
- **ROI**: [예: 3080% (31배 수익)]
- **회수 기간**: [예: 1.2개월]

---

## 7. 지속 가능성 및 모니터링

<!--
최적화는 끝이 아닌 시작
- 재발 방지
- 지속적인 성능 관리
- 알림 전략
-->

### 성능 모니터링 전략

#### Real-time Monitoring
- **APM 도구**: [New Relic, Datadog]
- **모니터링 대상**:
  - Application: 응답 시간, 처리량, 에러율
  - Database: Slow Query, 커넥션 수, Lock 대기
  - Cache: Hit/Miss Ratio, 메모리 사용률
  - Infrastructure: CPU, 메모리, 네트워크, 디스크

#### 알림 임계값 설정

| 지표 | Warning | Critical | 대응 |
|------|---------|----------|------|
| **평균 응답 시간** | > 300ms | > 500ms | Auto-scaling 트리거 |
| **에러율** | > 0.5% | > 1% | 온콜 담당자 호출 |
| **CPU 사용률** | > 70% | > 85% | 인스턴스 증설 |
| **DB 커넥션** | > 80% | > 90% | Pool 크기 증가 |

### 성능 회귀 방지

#### 1. 성능 테스트 자동화
```yaml
# CI/CD 파이프라인에 성능 테스트 통합
performance-test:
  stage: test
  script:
    - k6 run load-test.js
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
  allow_failure: false
  thresholds:
    - http_req_duration: ["p95<200"]  # P95 < 200ms
    - http_req_failed: ["rate<0.01"]  # 에러율 < 1%
```

#### 2. 성능 SLO (Service Level Objective)
- **Latency SLO**: P95 응답 시간 < 200ms (99% 요청)
- **Availability SLO**: 가용성 > 99.9%
- **Throughput SLO**: 최소 1000 TPS 처리 가능
- **Error Budget**: 월간 에러율 < 0.1%

#### 3. 코드 리뷰 체크리스트
성능 관련 코드 리뷰 시 확인 사항:
- [ ] N+1 쿼리 발생 가능성 확인
- [ ] 적절한 인덱스 사용 확인
- [ ] 캐시 전략 적용 확인
- [ ] 비동기 처리 가능 여부 확인
- [ ] Connection Pool 사이즈 적절성 확인
- [ ] 부하 테스트 수행 여부 확인

### 지속적 개선 계획

#### 단기 (1-3개월)
- [ ] [개선 항목 1 - 예: Redis Cluster 도입으로 캐시 확장성 확보]
- [ ] [개선 항목 2 - 예: DB Sharding으로 쓰기 부하 분산]

#### 중기 (3-6개월)
- [ ] [개선 항목 1 - 예: Kafka 도입으로 이벤트 기반 아키텍처 전환]
- [ ] [개선 항목 2 - 예: Elasticsearch 도입으로 검색 성능 개선]

#### 장기 (6개월+)
- [ ] [개선 항목 1 - 예: MSA 전환으로 도메인별 독립 확장]
- [ ] [개선 항목 2 - 예: Multi-region 배포로 글로벌 서비스 대응]

---

## 8. 테스트 검증 결과 (Test Verification)

### 8.1 부하 테스트 환경
```yaml
Test Tool: JMeter / Gatling / k6
Test Environment: Staging (동일 스펙)
Virtual Users: 100 → 500 → 1000 (단계적 증가)
Duration: 10분 (램프업 2분, 유지 6분, 램프다운 2분)
Test Scenario:
  - 로그인 API: 20%
  - 목록 조회 API: 50%
  - 상세 조회 API: 20%
  - 생성/수정 API: 10%
```

### 8.2 최적화 전 테스트 결과 (Before)
```
[부하 테스트 결과 - 동시 사용자 500명]
- 평균 응답 시간: 2,150ms
- P95 응답 시간: 4,800ms
- P99 응답 시간: 8,200ms
- 처리량: 85 TPS
- 에러율: 3.2%
- 서버 CPU: 92%
- 서버 메모리: 87%
```

### 8.3 최적화 후 테스트 결과 (After)
```
[부하 테스트 결과 - 동시 사용자 1000명]
- 평균 응답 시간: 145ms ✅ (93% 개선)
- P95 응답 시간: 280ms ✅ (94% 개선)
- P99 응답 시간: 420ms ✅ (95% 개선)
- 처리량: 1,850 TPS ✅ (22배 증가)
- 에러율: 0.02% ✅ (99% 개선)
- 서버 CPU: 55% ✅ (안정)
- 서버 메모리: 62% ✅ (안정)
```

### 8.4 테스트 결과 비교표
| 지표 | Before (500 VU) | After (1000 VU) | 개선율 | 목표 달성 |
|------|-----------------|-----------------|--------|-----------|
| 평균 응답 시간 | 2,150ms | 145ms | ↓ 93% | ✅ < 200ms |
| P95 응답 시간 | 4,800ms | 280ms | ↓ 94% | ✅ < 500ms |
| TPS | 85 | 1,850 | ↑ 22x | ✅ > 1000 |
| 에러율 | 3.2% | 0.02% | ↓ 99% | ✅ < 0.1% |

### 8.5 검증 체크리스트
- [ ] 부하 테스트에서 목표 TPS 달성 확인
- [ ] P95/P99 응답 시간 SLA 충족 확인
- [ ] 에러율 목표치 이하 확인
- [ ] 서버 리소스 안정성 확인
- [ ] 장시간 부하 테스트(Soak Test) 통과

---

## 9. 면접 Q&A (Interview Questions)

### Q1. 성능 문제를 어떻게 발견하고 분석했나요?
**A**: {성능 문제 발견 경위와 프로파일링 방법 설명}

**💡 포인트**:
- 모니터링 지표 (APM, CloudWatch, Prometheus)
- 프로파일링 도구 (JProfiler, VisualVM, New Relic)
- 병목 지점 분석 방법론

---

### Q2. 병목 지점을 파악하는 데 사용한 방법론은?
**A**: {병목 분석 방법론 설명}

**💡 포인트**:
- 계층별 분석 (Application → DB → Cache → Network → Infra)
- Slow Query 분석, Query Execution Plan
- Flame Graph 분석
- Amdahl's Law 적용

---

### Q3. 여러 최적화 기법 중 우선순위를 어떻게 정했나요?
**A**: {최적화 우선순위 결정 기준 설명}

**💡 포인트**:
- 영향도 × 난이도 매트릭스
- Quick Wins 먼저 적용
- 비용 대비 효과 분석
- 리스크 평가

---

### Q4. N+1 쿼리 문제를 어떻게 해결했나요? (해당시)
**A**: {N+1 문제 원인과 해결 방법 설명}

**💡 포인트**:
- ORM의 Lazy Loading 특성 이해
- Fetch Join, EntityGraph, BatchSize 적용
- QueryDSL/JPQL 최적화
- 측정 결과 제시 (쿼리 수, 응답 시간)

---

### Q5. 캐시 전략은 어떻게 설계했나요? (해당시)
**A**: {캐시 설계 전략 설명}

**💡 포인트**:
- 캐시 대상 선정 기준 (빈번한 조회, 변경 빈도 낮음)
- 캐시 무효화 전략 (TTL, Write-through, Write-behind)
- Cache-aside 패턴 적용
- Hit Rate 측정 및 최적화

---

### Q6. 이 최적화 경험에서 배운 점은?
**A**: {기술적/프로세스 측면의 교훈}

**💡 포인트**:
- "측정하지 않으면 개선할 수 없다"
- 점진적 최적화의 중요성
- 트레이드오프 이해 (성능 vs 복잡도 vs 비용)
- 지속적인 모니터링 체계 구축

---

## 📌 핵심 교훈 (Key Takeaways)

<!--
이 최적화 작업에서 배운 것
- 기술적 교훈
- 측정의 중요성
- 점진적 접근의 가치
-->

### 1. [첫 번째 교훈 - 측정]
- **상황**: [예: 추측 기반 최적화는 실패한다]
- **교훈**: [예: 항상 측정하고, 프로파일링하고, 데이터 기반으로 결정]
- **적용**: [예: 모든 최적화 전후 반드시 벤치마크 실행]

### 2. [두 번째 교훈 - 점진적 접근]
- **상황**: [예: 한 번에 모든 것을 바꾸려다 실패]
- **교훈**: [예: Quick Wins → 구조 개선 → 인프라 최적화 단계별 접근]
- **적용**: [예: 작은 성공을 쌓아가며 리스크 최소화]

### 3. [세 번째 교훈 - 트레이드오프]
- **상황**: [예: 성능과 복잡도, 비용의 균형]
- **교훈**: [예: 완벽한 해결책은 없다. 상황에 맞는 최선의 선택]
- **적용**: [예: 비즈니스 목표와 기술적 제약을 모두 고려한 의사결정]

---

## 🔗 관련 문서

<!--
관련된 다른 문서들 링크
- 성능 테스트 결과
- 아키텍처 문서
- 모니터링 대시보드
-->

- [성능 테스트 결과](./PERFORMANCE_TEST_RESULTS.md)
- [아키텍처 다이어그램](./ARCHITECTURE.md)
- [모니터링 대시보드](https://grafana.example.com/dashboard)
- [APM 대시보드](https://newrelic.example.com)
- [관련 기술 블로그 포스트](https://blog.example.com/performance-optimization)

---

## 📸 참고 자료

<!--
시각 자료 첨부
- 성능 측정 그래프
- 아키텍처 다이어그램
- 모니터링 스크린샷
-->

### 응답 시간 개선 그래프
```
[Before vs After 응답 시간 비교 그래프]

Before: ████████████████████ 2000ms
After:  ██ 150ms

92.5% 개선 ↓
```

### 처리량 증가 그래프
```
[TPS 증가 추이]

Before: ████ 100 TPS
After:  ████████████████████████████████████████ 2000 TPS

1900% 증가 ↑
```

### 인프라 아키텍처 변화
```
[Before/After 아키텍처 다이어그램]
위 섹션 5의 다이어그램 참조
```

---

**작성자**: [이름]
**최종 수정일**: YYYY년 MM월
**버전**: 1.0.0
